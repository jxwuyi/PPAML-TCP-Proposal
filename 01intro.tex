\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\tabref}[1]{Table~\ref{#1}}
\renewcommand{\eqref}[1]{Equation~(\ref{#1})}

\newcommand{\mbf}[1]{\mbox{{\bf #1}}}
\newcommand{\shortcite}{\cite}
\newcommand{\smbf}[1]{\mbox{{\scriptsize\bf #1}}}
\def\w{\mbf{w}}

%\section{Introduction}
%% {\centering\scriptsize\em
%%   Substantial portions of this text are reproduced from an
%%   author's paper~\cite{friedman1997image}.}

{\bf Foreground/Background Video Segmentation:}
Recognizing and tracking moving
objects is one of the main uses of vision.
For computer vision, we can start with `merely' identifying the
foreground.
%first identify what part of each
%frame is due to moving objects.
%(subsequently, separating and tracking
%individuals across frames are also important subproblems)
That is, the task here is to decompose
each frame of video into two parts: all of the moving objects, and
everything else.  Thankfully, in practice, approximate answers are
good enough.  \secref{sec:formal-problem} formally defines the problem,
but first, some background.

For many years, the ``obvious'' approach has
been first to compute some stationary {\em background image}, and then to
identify the moving objects as those pixels in each frame that
differ significantly from the background. We will call this the
{\em background subtraction} approach.
The details of the method are described briefly in
\secref{background-subtraction-section}.

To pick one application, the Roadwatch project at Berkeley,
background subtraction is overall an effective means of
locating and tracking moving vehicles in freeway
traffic~\cite{Koller+al:1994}.
However, in some important cases, background subtraction performs
poorly at vehicle detection: long shadows and heavy traffic.
Shadows move, but treating them as real parts of the vehicles they
overlap leads to many problems, starting with reliably separating each
vehicle from one another.
Moreover, background subtraction tends to treat any
sufficiently slowly changing pixel as
background, which is a problem in heavy traffic because vehicles
then too often disappear into the background.\footnote{Interestingly,
  many natural predators are also only able to see movement, so that
  freezing in place grants invisibility.}

These problems are not specific to freeway monitoring, as they arise
from the oversimplified view of the
general task---detecting moving objects---that
background subtraction takes.  Namely, the approach assumes that
background never changes and foreground always changes.  However,
occasionally-variable background and occasionally-constant
foreground are also possible.  Handling those, when important, needs a
more sophisticated approach; probabilistic techniques prove useful in practice,
especially the use of Expectation-Maximization (EM)~\cite{Dempster+al:1977}.

There is a large literature (several hundred papers in the last
decade, and several annual conferences) on the application
of EM and its family of closely related techniques
to image reconstruction, image segmentation, and
motion identification.   Applications include optical astronomy, laser
range finders, synthetic aperture radar, magnetic resonance imaging, PET, microscopy, and
X-rays.  Almost without exception, EM is used to identify classes of
pixels within an image or classes of motions within an optical flow
field, on the assumption that similar pixels can be grouped
together. Typical examples include Samadani~\cite{Samadani:1995},
Jepson and Black~\cite{Jepson+Black:1993}, Sawhney and
Ayer~\cite{Sawhney+Ayer:1996}, and Weiss and
Adelson~\cite{Weiss+Adelson:1996}.

\subsection{PPAML Motivation}

Interestingly, even just using a simple three-class (``background'', ``darkened'',
``occluded'') mixture model already significantly improves upon
background subtraction for the Roadwatch application~\cite{friedman1997image}.  See
\secref{shadow-and-background-subtraction-section} for a summary of
that approach---which we take as baseline.

This baseline is interesting firstly because it is a natural
probabilistic generalization of the 
classical deterministic approach.
Secondly and more importantly of interest, significant further
improvement should be possible, for example `just' developing and
applying a more complicated probabilistic model should work.

We note, however, that getting inference to work on our suggested baseline
model, on the real application, was not a small amount of
implementation effort.  That severely limited the scope of alternative models we could
feasibly investigate at that time.  A useful probabilistic programming
system would allow a much broader investigation into possible models,
by automating away some of the work presently required when working
from a language with little to no special support for probability.


\subsubsection{Reuse and Tuning}

We expect any implementation to `work' on any video input, although
the quality of the segmentation may be abysmal when core assumptions are
challenged.  For example, the baseline---and background
subtraction---critically assumes a stationary camera.  A moving camera
will provoke nonsense.

Besides that, while motivated from freeway
traffic, the baseline model and accompanying implementation  make few assumptions.
For example, the model does not assume that all shadows have to point
the same way.  We could have exploited that, and it would have yielded
better segmentations on freeway traffic data.  Since we did not build in any such assumption about light
sources, we expect that our model will perform the same at
identifying and ignoring shadows regardless of the number or geometry of light sources.

We hope that
any effort implementors do put into optimizing for some specific
assumptions about the kinds of videos that will be seen is easily
adapted to work well for other situations.  Patient-monitoring in
hospitals and facial-recognition at airports are two such potential applications
where one might expect a foreground-detector trained on freeway data
to still function reasonably well without further massive tuning/training.
It would be interesting to see the results of such cross-domain
application.  How much incremental work is needed by each PPS/team to get
acceptable results as noncritical assumptions change?


\subsubsection{Modularity}

As demonstrated by the existing work,
reasonably effective performance on the problem is easy enough to
achieve without relying on large, preexisting, machine vision
implementations.  That is helpful for those probabilistic programming
systems that limit callouts to other runtimes.

At the same time, getting the segmentation nearly as correct as a
human in every case has roughly the same structure as presently typical
CAPTCHAs (picking out objects in sufficiently complicated images and
videos is considered human-feasible but computer-infeasible).
If aiming for that or similarly high
levels of performance, then a PPS that permits reuse of
preexisting implementations could easily demonstrate a significant
advantage.


\subsubsection{Space Efficiency}

Video data is an interesting stress test of a PPS.  What is the
overhead the system accrues when representing distributions over
datastructures?  Likely too much by default, since uncompressed video
can be large
enough to stress test even deterministic languages.  It will be
interesting to see what answers each PPS provides for working with
models too big to entirely fit in memory all at once.  Is the effort
required to control the PPS's memory overhead more, or less, than the
effort required to implement probability theory in a deterministic
language?



%% To pick two
%% potential flaws of the reference work: it fails to consider nighttime
%% and deliberately ignores contiguity.
%% Much like shadows, the pixels brightened
%% by vehicles' headlights are easily misclassified as real parts of the
%% vehicles.  Using four classes
%% (``background'', ``brightened'', ``darkened'', ``occluded'') could help.
%% The reference work can be confused by a gray vehicle driving over a
%% gray manhole: it can mistakenly imagine that the manhole remains
%% visible when the vehicle drives over it.  Adding probabilistic contiguity
%% constraints would combat that and many related potential flaws.





%\subsection{Notation}
%\label{sec:notation}


\subsection{Foreground Video Segmentation}
\label{sec:formal-problem}

The goal is to take an input video and select a subset of each
frame---ideally in real-time---corresponding to whatever the notion of
``interesting'' is.  The selection of a subset of each frame is a
\emph{segmentation} of the original video; the selected subset is the
\emph{foreground} and its complement is the \emph{background}, the two
together are the segmentation of the frame.

Concretely, there are all sorts of hairy details to decide upon about the
precise representation, storage, and transmisison of input videos and
segmentations. In the online/real-time setting there are further details to
decide upon, in particular, limits on maximum 
and average latency (is 1 second too long?).

Abstractly, a video can be represented as a function $I(x,y,t)$ giving
the value at time $t$ of the pixel at $(x,y)$.  The frames will be
rectangular and fixed 
size, so $x$ is in some set $\{0,1,\ldots,n\}$ and $y$ is in another
$\{0,1,\ldots,m\}$.  The framerate will be constant, and so the domain
of time is just $\{0,1,\ldots,T\}$.  The nature of pixel values
(grayscale, RGB, HSV, CMYK, \ldots) will be specified and constant
(probably red, green, blue).

A segmentation can be represented as a mask, that is, as a function
$M(x,y,t)$ onto either 0 or 1.  ``1'' means ``interesting''; so
$M(150,60,70)=0$ is the assertion that, at time $70$, the pixel at
$(150,60)$ is background according to segmentation $M$.

It is often very useful, even necessary, to process video
\emph{online}, which here means to pick the segmentation of the
current frame in some bounded amount of time.  In that setting we
can emphasize time by writing $I_t(x,y)=I(x,y,t)$
for the current frame (the one at time $t$) and $M_t(x,y)=M(x,y,t)$
for its segmentation.  A typical constraint on such algorithms is to
compute an answer using only some bounded memory of the past: each
$M_t$ should depend on only $I_{t-k},\ldots, I_t$ for some $k$.

``Interesting'' will not be given an entirely formal
definition; intuitively, the interesting things are the things that
move.  But as mentioned, there are application-specific exceptions: a
stopped vehicle is interesting, a shadow is not.
A (partially?) labeled training set will exemplify the notion for
whatever source of video is chosen.
So the overall task is to both learn the concept (offline), and
predict it (ideally online).

A fully labeled training set is just some distinguished set of videos and
corresponding segmentations, usually somewhat imperfect:
$\{(I,M) \mid \text{$M$ is (probably, approximately) a correct
  segmentation of $I$}\}$ is the form of a training set.

The precise notion of quality of prediction will be specified, but in
practice the most appropriate definition varies wildly.  Ideally each
PPS will be able to easily adjust its behavior to suit a wide range of
plausible performance metrics.





%% Some systems/participants may want to communicate their uncertainty
%% about the interesting subset of each frame.  That is difficult to---and
%% we will not---accomodate, as there are too many ways to be uncertain.  For example,
%% our baseline would prefer to assign a probability to each pixel
%% (rather than 0/1).  Other approaches might want to consider spatial
%% dependencies, for example by presenting a (perhaps weighted) set of
%% sampled frames.  Still others might want to report a symbolic
%% representation of a distribution over the present frame.  The truly
%% ambituous consider also temporal dependencies (by working with
%% distributions over whole segmentations).

%% For evaluation purposes, we settle on the simplest thing, which is to
%% demand a single (most likely) estimate of each frame in turn.  Each
%% will then be scored by its distance to the notionally correct answer,
%% where ``distance'' will be some well-specified metric on frames (such
%% as ``number of correct foreground pixels'').  The
%% scores for each frame will then be aggregated in some specified
%% fashion (averaging, maxing, or something more exotic).
%% There is no
%% way to reach consensus on the best possible scoring or aggregation
%% functions (or even that the score of a segmentation should be any form
%% of aggregration of per-frame scores); any particular application has
%% its own peculiar set of consequences for being wrong.\footnote{It would be
%% better, for example, to optimize the probability of identifying any
%% fatal threat rather than to optimize the accuracy of ones estimate of
%% the total number of moving objects.}

%% An interesting meta-evaluation is to assess how easily each 
%% implementation can be adapted if the performance metric is changed.
%% Is the language flexible enough to explicitly model not only the
%% question, but also the full metric over wrong answers?

